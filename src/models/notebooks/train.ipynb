{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# generate sample data\n",
    "plt.figure(figsize=(8,5))\n",
    "# how many time steps/data pts are in one batch of data\n",
    "seq_length = 20\n",
    "# generate evenly spaced data pts\n",
    "time_steps = np.linspace(0, np.pi, seq_length + 1)\n",
    "data = np.sin(time_steps)\n",
    "data.resize((seq_length + 1, 1)) # size becomes (seq_length+1, 1), adds an input_size dimension\n",
    "x = data[:-1] # all but the last piece of data\n",
    "y = data[1:] # all but the first\n",
    "# display the data\n",
    "plt.plot(time_steps[1:], x, 'r.', label='input, x') # x\n",
    "plt.plot(time_steps[1:], y, 'b.', label='target, y') # y\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in datasets\n",
    "\n",
    "The datasets consist of:\n",
    "\n",
    "    - train.csv (a training dataset)\n",
    "    - test.csv (a test dataset)\n",
    "    - oil.csv, transactions.csv, holidays_events.csv (exogenous datasets)\n",
    "    - stores.csv (a dataset the links store information)\n",
    "\n",
    "The data is attached in the `data` folder in the `store-sales-time-series-forecasting.zip`, and can be unzipped using the `unzip` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cullenpaulisick/opt/anaconda3/envs/default_ml_dev/lib/python3.10/site-packages/numpy/lib/function_base.py:5071: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asarray(arr)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df = pd.read_csv(\"../../../data/train.csv\")\n",
    "test_df = pd.read_csv(\"../../../data/test.csv\")\n",
    "oil_df = pd.read_csv(\"../../../data/oil.csv\")\n",
    "\n",
    "# create sample dataset for training\n",
    "# merge and reset index\n",
    "train_df = train_df.merge(oil_df, on='date', how='left').dropna().set_index(\"id\").reset_index()\n",
    "\n",
    "# loader = DataLoader(list(zip(X,y)), shuffle=True, batch_size=16)\n",
    "def sales_by_store(data, family: str=\"AUTOMOTIVE\", col_include = ['date', 'sales']):\n",
    "    store_data = {}\n",
    "    for store in data.store_nbr.unique():\n",
    "        train_df = data.loc[data.family==family.upper()]\n",
    "        store_data[store] = train_df.loc[train_df.store_nbr==store][col_include].sort_values(by=\"date\", ascending=True).set_index(\"date\")\n",
    "        # create target by shifting data forward one period\n",
    "        store_data[store]['sales_shift'] = store_data[store].sales.shift(-1)\n",
    "        # drop remaining null position at last period\n",
    "        store_data[store].dropna(inplace=True)\n",
    "    return store_data\n",
    "\n",
    "def groups_of_size(arr: np.array, n: int=20):\n",
    "\n",
    "    chunk_indices = list(range(0, arr.size, n))\n",
    "    # remove first element to prevent 0-sized first element\n",
    "    chunk_indices.pop(0)\n",
    "    splits = np.split(arr, chunk_indices)\n",
    "    # remove last element if size is non-matching\n",
    "    if splits[-1].size != n:\n",
    "        splits = np.delete(splits, -1, 0)\n",
    "    \n",
    "    return np.vstack(splits) \n",
    "\n",
    "# get data for each store within sales family\n",
    "store_data = sales_by_store(train_df, col_include=['date', 'sales', 'dcoilwtico'])\n",
    "# for each store, append to create whole dataset\n",
    "\n",
    "sales = np.vstack([groups_of_size(df.sales.values, n=20) for df in store_data.values()])\n",
    "sales_shift = np.vstack([groups_of_size(df.sales_shift.values, n=20) for df in store_data.values()])\n",
    "oil = np.vstack([groups_of_size(df.dcoilwtico.values, n=20) for df in store_data.values()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dstack([sales, oil])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>dcoilwtico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1782</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1783</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1784</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1785</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>1091.000</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1786</td>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072461</th>\n",
       "      <td>3000883</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>POULTRY</td>\n",
       "      <td>438.133</td>\n",
       "      <td>0</td>\n",
       "      <td>47.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072462</th>\n",
       "      <td>3000884</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>154.553</td>\n",
       "      <td>1</td>\n",
       "      <td>47.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072463</th>\n",
       "      <td>3000885</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>2419.729</td>\n",
       "      <td>148</td>\n",
       "      <td>47.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072464</th>\n",
       "      <td>3000886</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>SCHOOL AND OFFICE SUPPLIES</td>\n",
       "      <td>121.000</td>\n",
       "      <td>8</td>\n",
       "      <td>47.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072465</th>\n",
       "      <td>3000887</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>9</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0</td>\n",
       "      <td>47.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2072466 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id        date  store_nbr                      family     sales   \n",
       "0           1782  2013-01-02          1                  AUTOMOTIVE     2.000  \\\n",
       "1           1783  2013-01-02          1                   BABY CARE     0.000   \n",
       "2           1784  2013-01-02          1                      BEAUTY     2.000   \n",
       "3           1785  2013-01-02          1                   BEVERAGES  1091.000   \n",
       "4           1786  2013-01-02          1                       BOOKS     0.000   \n",
       "...          ...         ...        ...                         ...       ...   \n",
       "2072461  3000883  2017-08-15          9                     POULTRY   438.133   \n",
       "2072462  3000884  2017-08-15          9              PREPARED FOODS   154.553   \n",
       "2072463  3000885  2017-08-15          9                     PRODUCE  2419.729   \n",
       "2072464  3000886  2017-08-15          9  SCHOOL AND OFFICE SUPPLIES   121.000   \n",
       "2072465  3000887  2017-08-15          9                     SEAFOOD    16.000   \n",
       "\n",
       "         onpromotion  dcoilwtico  \n",
       "0                  0       93.14  \n",
       "1                  0       93.14  \n",
       "2                  0       93.14  \n",
       "3                  0       93.14  \n",
       "4                  0       93.14  \n",
       "...              ...         ...  \n",
       "2072461            0       47.57  \n",
       "2072462            1       47.57  \n",
       "2072463          148       47.57  \n",
       "2072464            8       47.57  \n",
       "2072465            0       47.57  \n",
       "\n",
       "[2072466 rows x 7 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 4., 4., 1., 4., 4., 2., 4., 1., 2., 4., 6., 1., 7., 3., 0., 2., 2.,\n",
      "        1., 8.], dtype=torch.float64) tensor([4., 4., 1., 4., 4., 2., 4., 1., 2., 4., 6., 1., 7., 3., 0., 2., 2., 1.,\n",
      "        8., 7.], dtype=torch.float64)\n",
      "tensor([12.,  1.,  3.,  1.,  4., 10.,  9.,  5.,  1.,  1.,  5.,  3.,  2.,  1.,\n",
      "         3.,  0.,  4.,  0.,  2.,  4.], dtype=torch.float64) tensor([ 1.,  3.,  1.,  4., 10.,  9.,  5.,  1.,  1.,  5.,  3.,  2.,  1.,  3.,\n",
      "         0.,  4.,  0.,  2.,  4.,  2.], dtype=torch.float64)\n",
      "tensor([3., 3., 8., 4., 2., 8., 3., 7., 3., 9., 6., 0., 1., 4., 4., 6., 4., 1.,\n",
      "        4., 2.], dtype=torch.float64) tensor([3., 8., 4., 2., 8., 3., 7., 3., 9., 6., 0., 1., 4., 4., 6., 4., 1., 4.,\n",
      "        2., 8.], dtype=torch.float64)\n",
      "tensor([4., 3., 3., 5., 7., 3., 7., 9., 2., 7., 5., 4., 4., 3., 9., 9., 5., 4.,\n",
      "        9., 1.], dtype=torch.float64) tensor([3., 3., 5., 7., 3., 7., 9., 2., 7., 5., 4., 4., 3., 9., 9., 5., 4., 9.,\n",
      "        1., 6.], dtype=torch.float64)\n",
      "tensor([5., 1., 1., 4., 0., 1., 6., 4., 2., 1., 1., 1., 7., 2., 0., 5., 0., 2.,\n",
      "        4., 4.], dtype=torch.float64) tensor([1., 1., 4., 0., 1., 6., 4., 2., 1., 1., 1., 7., 2., 0., 5., 0., 2., 4.,\n",
      "        4., 0.], dtype=torch.float64)\n",
      "tensor([ 3.,  6., 10.,  1.,  4.,  2.,  3.,  1.,  1.,  5.,  6., 27.,  1.,  5.,\n",
      "         1., 11.,  2.,  5.,  6.,  0.], dtype=torch.float64) tensor([ 6., 10.,  1.,  4.,  2.,  3.,  1.,  1.,  5.,  6., 27.,  1.,  5.,  1.,\n",
      "        11.,  2.,  5.,  6.,  0.,  3.], dtype=torch.float64)\n",
      "tensor([ 2.,  1.,  2.,  1.,  2., 11.,  0.,  4.,  6.,  7.,  4.,  8.,  1.,  3.,\n",
      "         1., 10.,  7.,  7.,  1.,  6.], dtype=torch.float64) tensor([ 1.,  2.,  1.,  2., 11.,  0.,  4.,  6.,  7.,  4.,  8.,  1.,  3.,  1.,\n",
      "        10.,  7.,  7.,  1.,  6.,  4.], dtype=torch.float64)\n",
      "tensor([ 7.,  9.,  4.,  3.,  5., 15.,  4.,  7.,  3.,  4.,  7.,  7.,  5.,  7.,\n",
      "         1.,  5.,  1.,  4.,  1.,  1.], dtype=torch.float64) tensor([ 9.,  4.,  3.,  5., 15.,  4.,  7.,  3.,  4.,  7.,  7.,  5.,  7.,  1.,\n",
      "         5.,  1.,  4.,  1.,  1.,  9.], dtype=torch.float64)\n",
      "tensor([ 1.,  6.,  2.,  2.,  1.,  4.,  6.,  4., 10., 10.,  2.,  7., 15.,  7.,\n",
      "         5.,  3., 11.,  1.,  7.,  5.], dtype=torch.float64) tensor([ 6.,  2.,  2.,  1.,  4.,  6.,  4., 10., 10.,  2.,  7., 15.,  7.,  5.,\n",
      "         3., 11.,  1.,  7.,  5.,  1.], dtype=torch.float64)\n",
      "tensor([ 2.,  4., 11., 11.,  2.,  3.,  4.,  3.,  5.,  6.,  3.,  9.,  2.,  7.,\n",
      "         3.,  2.,  7.,  1.,  9., 10.], dtype=torch.float64) tensor([ 4., 11., 11.,  2.,  3.,  4.,  3.,  5.,  6.,  3.,  9.,  2.,  7.,  3.,\n",
      "         2.,  7.,  1.,  9., 10.,  5.], dtype=torch.float64)\n",
      "tensor([ 7., 14., 16., 16.,  9.,  7., 13., 30., 11.,  6., 13., 14.,  9., 13.,\n",
      "        16., 15., 15., 11., 17., 27.], dtype=torch.float64) tensor([14., 16., 16.,  9.,  7., 13., 30., 11.,  6., 13., 14.,  9., 13., 16.,\n",
      "        15., 15., 11., 17., 27., 21.], dtype=torch.float64)\n",
      "tensor([5., 4., 8., 9., 8., 7., 7., 2., 9., 6., 2., 7., 4., 5., 0., 7., 5., 9.,\n",
      "        5., 2.], dtype=torch.float64) tensor([4., 8., 9., 8., 7., 7., 2., 9., 6., 2., 7., 4., 5., 0., 7., 5., 9., 5.,\n",
      "        2., 9.], dtype=torch.float64)\n",
      "tensor([ 5.,  5.,  6.,  2., 19.,  4.,  8.,  6.,  4.,  5.,  3.,  3., 11.,  8.,\n",
      "         7.,  3.,  5.,  8.,  8.,  3.], dtype=torch.float64) tensor([ 5.,  6.,  2., 19.,  4.,  8.,  6.,  4.,  5.,  3.,  3., 11.,  8.,  7.,\n",
      "         3.,  5.,  8.,  8.,  3.,  2.], dtype=torch.float64)\n",
      "tensor([15.,  9.,  7., 11., 16., 20., 10., 13., 11.,  9., 12.,  9.,  6.,  3.,\n",
      "        11.,  8., 24.,  8., 11.,  7.], dtype=torch.float64) tensor([ 9.,  7., 11., 16., 20., 10., 13., 11.,  9., 12.,  9.,  6.,  3., 11.,\n",
      "         8., 24.,  8., 11.,  7., 24.], dtype=torch.float64)\n",
      "tensor([ 1.,  5.,  3.,  4.,  2.,  5.,  4.,  6.,  3.,  6.,  8.,  3.,  8.,  7.,\n",
      "         6.,  2., 11.,  2.,  3.,  4.], dtype=torch.float64) tensor([ 5.,  3.,  4.,  2.,  5.,  4.,  6.,  3.,  6.,  8.,  3.,  8.,  7.,  6.,\n",
      "         2., 11.,  2.,  3.,  4.,  0.], dtype=torch.float64)\n",
      "tensor([10.,  9., 14., 10.,  8., 27., 15., 15., 24., 15., 20., 20.,  4., 21.,\n",
      "        25., 31., 12., 14., 12.,  9.], dtype=torch.float64) tensor([ 9., 14., 10.,  8., 27., 15., 15., 24., 15., 20., 20.,  4., 21., 25.,\n",
      "        31., 12., 14., 12.,  9., 14.], dtype=torch.float64)\n",
      "tensor([ 6.,  2.,  7.,  6.,  4.,  7.,  4., 12.,  5.,  2.,  9., 10.,  5.,  7.,\n",
      "         4.,  4.,  2.,  3.,  5.,  5.], dtype=torch.float64) tensor([ 2.,  7.,  6.,  4.,  7.,  4., 12.,  5.,  2.,  9., 10.,  5.,  7.,  4.,\n",
      "         4.,  2.,  3.,  5.,  5., 11.], dtype=torch.float64)\n",
      "tensor([ 0.,  0.,  0.,  0.,  0., 10., 13.,  6.,  9.,  5.,  4.,  8.,  6.,  8.,\n",
      "         2.,  8.,  4.,  5.,  5.,  5.], dtype=torch.float64) tensor([ 0.,  0.,  0.,  0., 10., 13.,  6.,  9.,  5.,  4.,  8.,  6.,  8.,  2.,\n",
      "         8.,  4.,  5.,  5.,  5., 11.], dtype=torch.float64)\n",
      "tensor([4., 2., 3., 3., 4., 8., 1., 5., 7., 4., 3., 2., 4., 1., 2., 5., 1., 7.,\n",
      "        3., 2.], dtype=torch.float64) tensor([2., 3., 3., 4., 8., 1., 5., 7., 4., 3., 2., 4., 1., 2., 5., 1., 7., 3.,\n",
      "        2., 4.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)\n",
      "tensor([9., 4., 3., 3., 4., 7., 3., 0., 5., 2., 4., 1., 3., 1., 0., 3., 3., 2.,\n",
      "        5., 3.], dtype=torch.float64) tensor([4., 3., 3., 4., 7., 3., 0., 5., 2., 4., 1., 3., 1., 0., 3., 3., 2., 5.,\n",
      "        3., 2.], dtype=torch.float64)\n",
      "tensor([10.,  2.,  2.,  1.,  4.,  2.,  4.,  3.,  2.,  1.,  3.,  0.,  4.,  7.,\n",
      "         2.,  5.,  1.,  3.,  2.,  5.], dtype=torch.float64) tensor([2., 2., 1., 4., 2., 4., 3., 2., 1., 3., 0., 4., 7., 2., 5., 1., 3., 2.,\n",
      "        5., 3.], dtype=torch.float64)\n",
      "tensor([ 3.,  4., 16.,  8., 19.,  2.,  2.,  1.,  7.,  4.,  7., 10.,  4.,  1.,\n",
      "         9.,  5.,  1.,  1.,  4.,  6.], dtype=torch.float64) tensor([ 4., 16.,  8., 19.,  2.,  2.,  1.,  7.,  4.,  7., 10.,  4.,  1.,  9.,\n",
      "         5.,  1.,  1.,  4.,  6.,  0.], dtype=torch.float64)\n",
      "tensor([ 4.,  5.,  4.,  7.,  9.,  6.,  1.,  7.,  7., 15.,  6.,  3.,  7.,  6.,\n",
      "         4.,  3.,  7., 11.,  2.,  6.], dtype=torch.float64) tensor([ 5.,  4.,  7.,  9.,  6.,  1.,  7.,  7., 15.,  6.,  3.,  7.,  6.,  4.,\n",
      "         3.,  7., 11.,  2.,  6.,  3.], dtype=torch.float64)\n",
      "tensor([12., 14., 10., 10.,  7., 45., 14., 10., 18., 25.,  9., 24., 27., 12.,\n",
      "        11., 16.,  5.,  8., 11., 15.], dtype=torch.float64) tensor([14., 10., 10.,  7., 45., 14., 10., 18., 25.,  9., 24., 27., 12., 11.,\n",
      "        16.,  5.,  8., 11., 15.,  4.], dtype=torch.float64)\n",
      "tensor([7., 1., 4., 2., 7., 0., 3., 0., 1., 0., 4., 1., 0., 4., 0., 1., 2., 0.,\n",
      "        0., 2.], dtype=torch.float64) tensor([1., 4., 2., 7., 0., 3., 0., 1., 0., 4., 1., 0., 4., 0., 1., 2., 0., 0.,\n",
      "        2., 2.], dtype=torch.float64)\n",
      "tensor([ 1., 10.,  3.,  3.,  2.,  1.,  6.,  2.,  4.,  1.,  6.,  8.,  3.,  3.,\n",
      "         2.,  4.,  6.,  3.,  2.,  1.], dtype=torch.float64) tensor([10.,  3.,  3.,  2.,  1.,  6.,  2.,  4.,  1.,  6.,  8.,  3.,  3.,  2.,\n",
      "         4.,  6.,  3.,  2.,  1.,  0.], dtype=torch.float64)\n",
      "tensor([1., 2., 2., 6., 2., 4., 4., 2., 0., 1., 4., 4., 3., 5., 6., 3., 0., 3.,\n",
      "        2., 0.], dtype=torch.float64) tensor([2., 2., 6., 2., 4., 4., 2., 0., 1., 4., 4., 3., 5., 6., 3., 0., 3., 2.,\n",
      "        0., 2.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)\n",
      "tensor([ 7.,  2.,  8., 10.,  3.,  5.,  2.,  5.,  6.,  3.,  3.,  3.,  4.,  3.,\n",
      "         6., 10.,  7.,  8.,  6.,  3.], dtype=torch.float64) tensor([ 2.,  8., 10.,  3.,  5.,  2.,  5.,  6.,  3.,  3.,  3.,  4.,  3.,  6.,\n",
      "        10.,  7.,  8.,  6.,  3.,  4.], dtype=torch.float64)\n",
      "tensor([11.,  3.,  3.,  9.,  2.,  9.,  4.,  1.,  3.,  4.,  3.,  1.,  1.,  7.,\n",
      "         8.,  8.,  0., 12.,  1.,  2.], dtype=torch.float64) tensor([ 3.,  3.,  9.,  2.,  9.,  4.,  1.,  3.,  4.,  3.,  1.,  1.,  7.,  8.,\n",
      "         8.,  0., 12.,  1.,  2., 10.], dtype=torch.float64)\n",
      "tensor([4., 6., 0., 4., 3., 1., 5., 4., 1., 5., 1., 4., 1., 3., 2., 6., 1., 4.,\n",
      "        1., 3.], dtype=torch.float64) tensor([6., 0., 4., 3., 1., 5., 4., 1., 5., 1., 4., 1., 3., 2., 6., 1., 4., 1.,\n",
      "        3., 1.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)\n",
      "tensor([ 8.,  5.,  1.,  2.,  3.,  1.,  1.,  2.,  2., 11.,  2.,  0.,  0.,  1.,\n",
      "         9.,  3.,  3.,  1.,  0., 63.], dtype=torch.float64) tensor([ 5.,  1.,  2.,  3.,  1.,  1.,  2.,  2., 11.,  2.,  0.,  0.,  1.,  9.,\n",
      "         3.,  3.,  1.,  0., 63.,  2.], dtype=torch.float64)\n",
      "tensor([ 1.,  0.,  0.,  6.,  8.,  3.,  1.,  3.,  4.,  7.,  4.,  1.,  8.,  5.,\n",
      "         1.,  5.,  1.,  3., 10.,  5.], dtype=torch.float64) tensor([ 0.,  0.,  6.,  8.,  3.,  1.,  3.,  4.,  7.,  4.,  1.,  8.,  5.,  1.,\n",
      "         5.,  1.,  3., 10.,  5.,  2.], dtype=torch.float64)\n",
      "tensor([8., 5., 3., 4., 1., 1., 2., 5., 1., 0., 3., 4., 2., 2., 2., 3., 0., 3.,\n",
      "        3., 2.], dtype=torch.float64) tensor([5., 3., 4., 1., 1., 2., 5., 1., 0., 3., 4., 2., 2., 2., 3., 0., 3., 3.,\n",
      "        2., 2.], dtype=torch.float64)\n",
      "tensor([0., 3., 1., 1., 2., 1., 4., 2., 0., 3., 3., 5., 2., 0., 1., 0., 2., 1.,\n",
      "        4., 1.], dtype=torch.float64) tensor([3., 1., 1., 2., 1., 4., 2., 0., 3., 3., 5., 2., 0., 1., 0., 2., 1., 4.,\n",
      "        1., 4.], dtype=torch.float64)\n",
      "tensor([ 4.,  2.,  4.,  4.,  5.,  5.,  6.,  5.,  7.,  4.,  5.,  7.,  6.,  4.,\n",
      "        26., 12., 10.,  3.,  4.,  2.], dtype=torch.float64) tensor([ 2.,  4.,  4.,  5.,  5.,  6.,  5.,  7.,  4.,  5.,  7.,  6.,  4., 26.,\n",
      "        12., 10.,  3.,  4.,  2.,  3.], dtype=torch.float64)\n",
      "tensor([ 9.,  0.,  5.,  6., 10.,  8.,  7.,  3.,  4.,  6.,  6.,  5.,  9.,  7.,\n",
      "         9.,  6.,  5.,  2.,  6.,  8.], dtype=torch.float64) tensor([ 0.,  5.,  6., 10.,  8.,  7.,  3.,  4.,  6.,  6.,  5.,  9.,  7.,  9.,\n",
      "         6.,  5.,  2.,  6.,  8.,  7.], dtype=torch.float64)\n",
      "tensor([ 8.,  7.,  6.,  5.,  2.,  7.,  2.,  6., 10.,  3.,  9.,  8.,  6., 13.,\n",
      "         8.,  9.,  3.,  3., 10.,  5.], dtype=torch.float64) tensor([ 7.,  6.,  5.,  2.,  7.,  2.,  6., 10.,  3.,  9.,  8.,  6., 13.,  8.,\n",
      "         9.,  3.,  3., 10.,  5.,  6.], dtype=torch.float64)\n",
      "tensor([ 6.,  3.,  2.,  2.,  8., 21.,  0.,  2.,  5.,  4.,  2., 13.,  3., 19.,\n",
      "        16.,  1., 11.,  6.,  4.,  4.], dtype=torch.float64) tensor([ 3.,  2.,  2.,  8., 21.,  0.,  2.,  5.,  4.,  2., 13.,  3., 19., 16.,\n",
      "         1., 11.,  6.,  4.,  4.,  9.], dtype=torch.float64)\n",
      "tensor([13.,  9.,  6.,  8.,  7., 10.,  5., 10.,  4.,  5., 10.,  8.,  9.,  8.,\n",
      "        18., 15.,  6.,  7.,  8.,  3.], dtype=torch.float64) tensor([ 9.,  6.,  8.,  7., 10.,  5., 10.,  4.,  5., 10.,  8.,  9.,  8., 18.,\n",
      "        15.,  6.,  7.,  8.,  3.,  7.], dtype=torch.float64)\n",
      "tensor([ 5.,  6.,  6.,  1.,  3.,  3.,  3.,  0.,  3.,  8.,  2., 12.,  3.,  4.,\n",
      "         4.,  2.,  2.,  7.,  3.,  2.], dtype=torch.float64) tensor([ 6.,  6.,  1.,  3.,  3.,  3.,  0.,  3.,  8.,  2., 12.,  3.,  4.,  4.,\n",
      "         2.,  2.,  7.,  3.,  2.,  6.], dtype=torch.float64)\n",
      "tensor([ 7.,  9.,  6., 16., 12., 13., 10.,  9., 18.,  5.,  9.,  3.,  7.,  9.,\n",
      "         8.,  4., 15., 10.,  7., 12.], dtype=torch.float64) tensor([ 9.,  6., 16., 12., 13., 10.,  9., 18.,  5.,  9.,  3.,  7.,  9.,  8.,\n",
      "         4., 15., 10.,  7., 12.,  7.], dtype=torch.float64)\n",
      "tensor([ 4.,  1.,  1.,  0.,  1.,  4.,  0.,  4.,  2.,  2.,  3.,  4.,  4.,  2.,\n",
      "         2.,  5.,  2., 10.,  1.,  3.], dtype=torch.float64) tensor([ 1.,  1.,  0.,  1.,  4.,  0.,  4.,  2.,  2.,  3.,  4.,  4.,  2.,  2.,\n",
      "         5.,  2., 10.,  1.,  3.,  2.], dtype=torch.float64)\n",
      "tensor([12.,  8.,  8.,  9.,  2., 16.,  8.,  9.,  2.,  8.,  6.,  3.,  8., 13.,\n",
      "         5.,  5.,  5.,  6.,  3.,  9.], dtype=torch.float64) tensor([ 8.,  8.,  9.,  2., 16.,  8.,  9.,  2.,  8.,  6.,  3.,  8., 13.,  5.,\n",
      "         5.,  5.,  6.,  3.,  9., 13.], dtype=torch.float64)\n",
      "tensor([2., 1., 0., 5., 1., 4., 1., 1., 5., 1., 0., 1., 5., 0., 2., 1., 3., 3.,\n",
      "        1., 5.], dtype=torch.float64) tensor([1., 0., 5., 1., 4., 1., 1., 5., 1., 0., 1., 5., 0., 2., 1., 3., 3., 1.,\n",
      "        5., 2.], dtype=torch.float64)\n",
      "tensor([23., 32.,  5.,  9., 14.,  9., 10.,  8.,  9.,  2., 10.,  4., 30., 10.,\n",
      "         7., 11.,  4.,  6.,  5., 13.], dtype=torch.float64) tensor([32.,  5.,  9., 14.,  9., 10.,  8.,  9.,  2., 10.,  4., 30., 10.,  7.,\n",
      "        11.,  4.,  6.,  5., 13., 18.], dtype=torch.float64)\n",
      "tensor([ 5.,  4.,  4.,  9., 10., 11., 13.,  7.,  9., 11.,  7.,  7.,  3.,  8.,\n",
      "        14.,  4., 11.,  7.,  1.,  3.], dtype=torch.float64) tensor([ 4.,  4.,  9., 10., 11., 13.,  7.,  9., 11.,  7.,  7.,  3.,  8., 14.,\n",
      "         4., 11.,  7.,  1.,  3.,  3.], dtype=torch.float64)\n",
      "tensor([3., 2., 2., 4., 8., 0., 5., 2., 6., 2., 5., 4., 3., 4., 3., 4., 3., 9.,\n",
      "        0., 5.], dtype=torch.float64) tensor([2., 2., 4., 8., 0., 5., 2., 6., 2., 5., 4., 3., 4., 3., 4., 3., 9., 0.,\n",
      "        5., 2.], dtype=torch.float64)\n",
      "tensor([11.,  7., 10.,  9., 12., 11., 29., 11., 12., 30., 17., 24., 25., 35.,\n",
      "        32., 10., 24.,  8.,  9.,  9.], dtype=torch.float64) tensor([ 7., 10.,  9., 12., 11., 29., 11., 12., 30., 17., 24., 25., 35., 32.,\n",
      "        10., 24.,  8.,  9.,  9.,  3.], dtype=torch.float64)\n",
      "tensor([ 2.,  3.,  9.,  6.,  8.,  3.,  6.,  2.,  4.,  8.,  1.,  9.,  4., 14.,\n",
      "         3.,  3.,  7.,  4., 15., 10.], dtype=torch.float64) tensor([ 3.,  9.,  6.,  8.,  3.,  6.,  2.,  4.,  8.,  1.,  9.,  4., 14.,  3.,\n",
      "         3.,  7.,  4., 15., 10.,  4.], dtype=torch.float64)\n",
      "tensor([ 4.,  6., 12.,  4., 10., 18.,  4., 10.,  3.,  6.,  8., 11.,  3.,  9.,\n",
      "        13.,  7., 11.,  4., 11.,  8.], dtype=torch.float64) tensor([ 6., 12.,  4., 10., 18.,  4., 10.,  3.,  6.,  8., 11.,  3.,  9., 13.,\n",
      "         7., 11.,  4., 11.,  8.,  6.], dtype=torch.float64)\n",
      "tensor([2., 9., 7., 3., 1., 9., 6., 2., 3., 5., 7., 1., 0., 4., 4., 5., 8., 1.,\n",
      "        2., 5.], dtype=torch.float64) tensor([9., 7., 3., 1., 9., 6., 2., 3., 5., 7., 1., 0., 4., 4., 5., 8., 1., 2.,\n",
      "        5., 0.], dtype=torch.float64)\n",
      "tensor([11.,  7., 20.,  8.,  4.,  7.,  6., 10.,  3., 17.,  9., 12.,  8., 16.,\n",
      "         6., 10.,  4., 25.,  6., 25.], dtype=torch.float64) tensor([ 7., 20.,  8.,  4.,  7.,  6., 10.,  3., 17.,  9., 12.,  8., 16.,  6.,\n",
      "        10.,  4., 25.,  6., 25., 24.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)\n",
      "tensor([ 7.,  1.,  9.,  2.,  6.,  2.,  5.,  4.,  1.,  4., 14.,  3.,  4.,  3.,\n",
      "         3.,  2.,  8., 17.,  7.,  8.], dtype=torch.float64) tensor([ 1.,  9.,  2.,  6.,  2.,  5.,  4.,  1.,  4., 14.,  3.,  4.,  3.,  3.,\n",
      "         2.,  8., 17.,  7.,  8., 12.], dtype=torch.float64)\n",
      "tensor([ 2.,  2.,  2.,  3.,  2.,  2.,  3.,  2.,  5.,  3.,  3.,  2.,  3.,  4.,\n",
      "         0., 13.,  0.,  2.,  1.,  2.], dtype=torch.float64) tensor([ 2.,  2.,  3.,  2.,  2.,  3.,  2.,  5.,  3.,  3.,  2.,  3.,  4.,  0.,\n",
      "        13.,  0.,  2.,  1.,  2.,  1.], dtype=torch.float64)\n",
      "tensor([2., 5., 1., 1., 4., 1., 0., 5., 1., 5., 0., 4., 0., 0., 5., 1., 0., 1.,\n",
      "        1., 3.], dtype=torch.float64) tensor([5., 1., 1., 4., 1., 0., 5., 1., 5., 0., 4., 0., 0., 5., 1., 0., 1., 1.,\n",
      "        3., 3.], dtype=torch.float64)\n",
      "tensor([ 6.,  3.,  2.,  5.,  1.,  5.,  3.,  4.,  8., 10.,  6.,  0.,  2.,  6.,\n",
      "         2.,  5.,  0.,  5.,  2.,  1.], dtype=torch.float64) tensor([ 3.,  2.,  5.,  1.,  5.,  3.,  4.,  8., 10.,  6.,  0.,  2.,  6.,  2.,\n",
      "         5.,  0.,  5.,  2.,  1.,  0.], dtype=torch.float64)\n",
      "tensor([ 2.,  2.,  5.,  1.,  6.,  1.,  7.,  4.,  2.,  0.,  5.,  5., 11.,  4.,\n",
      "         6.,  8.,  6.,  4.,  2.,  8.], dtype=torch.float64) tensor([ 2.,  5.,  1.,  6.,  1.,  7.,  4.,  2.,  0.,  5.,  5., 11.,  4.,  6.,\n",
      "         8.,  6.,  4.,  2.,  8.,  3.], dtype=torch.float64)\n",
      "tensor([0., 1., 4., 2., 4., 3., 1., 2., 1., 3., 0., 1., 3., 3., 2., 2., 1., 2.,\n",
      "        3., 5.], dtype=torch.float64) tensor([1., 4., 2., 4., 3., 1., 2., 1., 3., 0., 1., 3., 3., 2., 2., 1., 2., 3.,\n",
      "        5., 3.], dtype=torch.float64)\n",
      "tensor([ 2., 14., 14., 10.,  4.,  4.,  3.,  7., 20.,  4., 11., 14., 14.,  7.,\n",
      "         6.,  8.,  8.,  8.,  5.,  9.], dtype=torch.float64) tensor([14., 14., 10.,  4.,  4.,  3.,  7., 20.,  4., 11., 14., 14.,  7.,  6.,\n",
      "         8.,  8.,  8.,  5.,  9.,  7.], dtype=torch.float64)\n",
      "tensor([16.,  7., 18.,  6., 18., 14., 20., 10., 17., 10., 14., 25., 11., 12.,\n",
      "        25., 40., 11., 11., 16., 19.], dtype=torch.float64) tensor([ 7., 18.,  6., 18., 14., 20., 10., 17., 10., 14., 25., 11., 12., 25.,\n",
      "        40., 11., 11., 16., 19.,  8.], dtype=torch.float64)\n",
      "tensor([14.,  7., 10., 17., 17., 15., 19., 26., 13., 15., 13., 31., 39., 28.,\n",
      "        18., 23., 11.,  8., 12., 16.], dtype=torch.float64) tensor([ 7., 10., 17., 17., 15., 19., 26., 13., 15., 13., 31., 39., 28., 18.,\n",
      "        23., 11.,  8., 12., 16., 10.], dtype=torch.float64)\n",
      "tensor([ 1.,  4.,  4.,  2.,  3.,  1.,  4.,  8.,  2.,  2.,  1.,  6., 10.,  3.,\n",
      "         0.,  4.,  4.,  1., 12.,  4.], dtype=torch.float64) tensor([ 4.,  4.,  2.,  3.,  1.,  4.,  8.,  2.,  2.,  1.,  6., 10.,  3.,  0.,\n",
      "         4.,  4.,  1., 12.,  4.,  3.], dtype=torch.float64)\n",
      "tensor([ 2.,  9.,  5.,  8.,  4.,  1.,  3.,  4.,  5.,  5.,  3.,  8., 10.,  2.,\n",
      "        11.,  1.,  5., 10.,  7.,  5.], dtype=torch.float64) tensor([ 9.,  5.,  8.,  4.,  1.,  3.,  4.,  5.,  5.,  3.,  8., 10.,  2., 11.,\n",
      "         1.,  5., 10.,  7.,  5.,  3.], dtype=torch.float64)\n",
      "tensor([6., 1., 4., 5., 6., 4., 2., 0., 0., 7., 4., 2., 1., 6., 1., 4., 2., 0.,\n",
      "        2., 2.], dtype=torch.float64) tensor([1., 4., 5., 6., 4., 2., 0., 0., 7., 4., 2., 1., 6., 1., 4., 2., 0., 2.,\n",
      "        2., 2.], dtype=torch.float64)\n",
      "tensor([8., 1., 2., 0., 3., 1., 0., 0., 2., 2., 0., 4., 2., 5., 1., 1., 5., 1.,\n",
      "        1., 1.], dtype=torch.float64) tensor([1., 2., 0., 3., 1., 0., 0., 2., 2., 0., 4., 2., 5., 1., 1., 5., 1., 1.,\n",
      "        1., 4.], dtype=torch.float64)\n",
      "tensor([ 7.,  4., 15., 12.,  6.,  6.,  5., 15., 12.,  5., 10.,  4.,  1.,  8.,\n",
      "        12.,  5.,  9.,  8.,  7.,  3.], dtype=torch.float64) tensor([ 4., 15., 12.,  6.,  6.,  5., 15., 12.,  5., 10.,  4.,  1.,  8., 12.,\n",
      "         5.,  9.,  8.,  7.,  3.,  6.], dtype=torch.float64)\n",
      "tensor([1., 1., 9., 4., 3., 0., 5., 4., 4., 4., 3., 7., 4., 8., 5., 9., 3., 3.,\n",
      "        9., 4.], dtype=torch.float64) tensor([1., 9., 4., 3., 0., 5., 4., 4., 4., 3., 7., 4., 8., 5., 9., 3., 3., 9.,\n",
      "        4., 1.], dtype=torch.float64)\n",
      "tensor([ 4., 14.,  2., 15.,  1.,  5.,  6.,  0.,  5.,  4.,  4.,  3.,  3.,  5.,\n",
      "         3.,  1.,  1.,  5.,  2.,  4.], dtype=torch.float64) tensor([14.,  2., 15.,  1.,  5.,  6.,  0.,  5.,  4.,  4.,  3.,  3.,  5.,  3.,\n",
      "         1.,  1.,  5.,  2.,  4.,  3.], dtype=torch.float64)\n",
      "tensor([ 9.,  9.,  6.,  7., 12., 30.,  5., 10.,  5., 26.,  5.,  9.,  8., 13.,\n",
      "        26., 14.,  4.,  6.,  3., 20.], dtype=torch.float64) tensor([ 9.,  6.,  7., 12., 30.,  5., 10.,  5., 26.,  5.,  9.,  8., 13., 26.,\n",
      "        14.,  4.,  6.,  3., 20.,  6.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)\n",
      "tensor([3., 2., 4., 4., 4., 2., 1., 3., 3., 5., 3., 2., 4., 1., 7., 4., 6., 9.,\n",
      "        0., 2.], dtype=torch.float64) tensor([2., 4., 4., 4., 2., 1., 3., 3., 5., 3., 2., 4., 1., 7., 4., 6., 9., 0.,\n",
      "        2., 9.], dtype=torch.float64)\n",
      "tensor([ 7.,  7.,  8.,  7.,  5.,  4.,  7.,  4.,  3.,  6.,  8.,  6.,  4.,  4.,\n",
      "         6., 12.,  8.,  3.,  5., 10.], dtype=torch.float64) tensor([ 7.,  8.,  7.,  5.,  4.,  7.,  4.,  3.,  6.,  8.,  6.,  4.,  4.,  6.,\n",
      "        12.,  8.,  3.,  5., 10., 10.], dtype=torch.float64)\n",
      "tensor([17.,  6., 14., 14., 16., 27., 19., 18., 16., 21., 12., 14., 25., 14.,\n",
      "        19., 19., 13., 17.,  3., 17.], dtype=torch.float64) tensor([ 6., 14., 14., 16., 27., 19., 18., 16., 21., 12., 14., 25., 14., 19.,\n",
      "        19., 13., 17.,  3., 17., 21.], dtype=torch.float64)\n",
      "tensor([13.,  5.,  6.,  6., 12., 10.,  3.,  1.,  6.,  5.,  4.,  3.,  3.,  4.,\n",
      "         8., 13.,  7.,  3., 26.,  9.], dtype=torch.float64) tensor([ 5.,  6.,  6., 12., 10.,  3.,  1.,  6.,  5.,  4.,  3.,  3.,  4.,  8.,\n",
      "        13.,  7.,  3., 26.,  9.,  6.], dtype=torch.float64)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64)\n",
      "tensor([2., 1., 2., 5., 5., 5., 2., 0., 5., 6., 5., 3., 5., 6., 9., 4., 6., 4.,\n",
      "        2., 1.], dtype=torch.float64) tensor([1., 2., 5., 5., 5., 2., 0., 5., 6., 5., 3., 5., 6., 9., 4., 6., 4., 2.,\n",
      "        1., 6.], dtype=torch.float64)\n",
      "tensor([ 5.,  4.,  6., 14.,  5.,  3.,  3.,  2.,  1.,  3.,  3.,  4.,  2.,  3.,\n",
      "         7.,  3.,  8.,  3.,  7.,  3.], dtype=torch.float64) tensor([ 4.,  6., 14.,  5.,  3.,  3.,  2.,  1.,  3.,  3.,  4.,  2.,  3.,  7.,\n",
      "         3.,  8.,  3.,  7.,  3.,  5.], dtype=torch.float64)\n",
      "tensor([ 0., 10.,  4.,  3.,  7.,  1.,  0.,  0.,  0.,  2.,  6.,  1.,  4.,  2.,\n",
      "         0.,  5.,  6.,  3.,  7.,  3.], dtype=torch.float64) tensor([10.,  4.,  3.,  7.,  1.,  0.,  0.,  0.,  2.,  6.,  1.,  4.,  2.,  0.,\n",
      "         5.,  6.,  3.,  7.,  3.,  8.], dtype=torch.float64)\n",
      "tensor([ 3.,  2.,  2.,  2.,  0.,  1.,  4.,  3.,  6.,  3.,  2.,  3.,  3.,  6.,\n",
      "         6.,  7.,  5.,  9.,  3., 13.], dtype=torch.float64) tensor([ 2.,  2.,  2.,  0.,  1.,  4.,  3.,  6.,  3.,  2.,  3.,  3.,  6.,  6.,\n",
      "         7.,  5.,  9.,  3., 13.,  1.], dtype=torch.float64)\n",
      "tensor([0., 1., 1., 2., 0., 2., 3., 1., 0., 3., 0., 1., 5., 1., 1., 3., 0., 1.,\n",
      "        2., 1.], dtype=torch.float64) tensor([1., 1., 2., 0., 2., 3., 1., 0., 3., 0., 1., 5., 1., 1., 3., 0., 1., 2.,\n",
      "        1., 4.], dtype=torch.float64)\n",
      "tensor([ 0.,  0.,  0.,  2.,  4.,  0.,  2.,  0.,  1.,  3.,  1.,  0.,  6., 10.,\n",
      "         2.,  3.,  3.,  3.,  1.,  2.], dtype=torch.float64) tensor([ 0.,  0.,  2.,  4.,  0.,  2.,  0.,  1.,  3.,  1.,  0.,  6., 10.,  2.,\n",
      "         3.,  3.,  3.,  1.,  2.,  5.], dtype=torch.float64)\n",
      "tensor([12.,  8., 36., 21., 13., 13., 23., 14., 11.,  8., 16.,  5., 12.,  9.,\n",
      "        17.,  8., 15., 16., 14., 25.], dtype=torch.float64) tensor([ 8., 36., 21., 13., 13., 23., 14., 11.,  8., 16.,  5., 12.,  9., 17.,\n",
      "         8., 15., 16., 14., 25., 17.], dtype=torch.float64)\n",
      "tensor([ 3.,  6.,  3.,  2.,  4.,  1.,  2.,  2.,  2.,  4.,  3.,  4.,  5., 12.,\n",
      "        11.,  1.,  2., 39.,  2.,  3.], dtype=torch.float64) tensor([ 6.,  3.,  2.,  4.,  1.,  2.,  2.,  2.,  4.,  3.,  4.,  5., 12., 11.,\n",
      "         1.,  2., 39.,  2.,  3.,  4.], dtype=torch.float64)\n",
      "tensor([ 5.,  2.,  1.,  5.,  9.,  2.,  1.,  2., 16.,  4.,  4.,  5.,  2.,  0.,\n",
      "         3.,  5.,  3.,  3.,  8.,  5.], dtype=torch.float64) tensor([ 2.,  1.,  5.,  9.,  2.,  1.,  2., 16.,  4.,  4.,  5.,  2.,  0.,  3.,\n",
      "         5.,  3.,  3.,  8.,  5.,  2.], dtype=torch.float64)\n",
      "tensor([14.,  5., 17.,  3.,  8., 10., 13., 18., 21., 11.,  6., 13., 20.,  9.,\n",
      "        12.,  8.,  7.,  8.,  7.,  5.], dtype=torch.float64) tensor([ 5., 17.,  3.,  8., 10., 13., 18., 21., 11.,  6., 13., 20.,  9., 12.,\n",
      "         8.,  7.,  8.,  7.,  5., 15.], dtype=torch.float64)\n",
      "tensor([15.,  3.,  1.,  1.,  0.,  4.,  4., 10.,  4.,  1.,  3.,  6.,  5.,  3.,\n",
      "         1.,  2., 14.,  5., 11.,  1.], dtype=torch.float64) tensor([ 3.,  1.,  1.,  0.,  4.,  4., 10.,  4.,  1.,  3.,  6.,  5.,  3.,  1.,\n",
      "         2., 14.,  5., 11.,  1.,  4.], dtype=torch.float64)\n",
      "tensor([ 4.,  3., 13.,  3.,  2.,  4.,  4.,  0.,  4.,  2.,  2.,  2.,  6.,  6.,\n",
      "        18.,  3.,  3.,  2.,  0.,  3.], dtype=torch.float64) tensor([ 3., 13.,  3.,  2.,  4.,  4.,  0.,  4.,  2.,  2.,  2.,  6.,  6., 18.,\n",
      "         3.,  3.,  2.,  0.,  3.,  2.], dtype=torch.float64)\n",
      "tensor([ 0.,  8.,  4.,  9.,  8., 21.,  5.,  6.,  9., 12.,  8.,  9.,  8., 12.,\n",
      "        13.,  6., 17.,  6.,  9., 13.], dtype=torch.float64) tensor([ 8.,  4.,  9.,  8., 21.,  5.,  6.,  9., 12.,  8.,  9.,  8., 12., 13.,\n",
      "         6., 17.,  6.,  9., 13.,  5.], dtype=torch.float64)\n",
      "tensor([1., 2., 0., 0., 2., 1., 4., 1., 3., 4., 2., 3., 1., 0., 1., 2., 2., 5.,\n",
      "        5., 3.], dtype=torch.float64) tensor([2., 0., 0., 2., 1., 4., 1., 3., 4., 2., 3., 1., 0., 1., 2., 2., 5., 5.,\n",
      "        3., 1.], dtype=torch.float64)\n",
      "tensor([11.,  4.,  7., 11.,  4.,  9.,  8.,  6., 11.,  7.,  5., 10.,  3.,  6.,\n",
      "        15.,  4.,  2., 10.,  2., 10.], dtype=torch.float64) tensor([ 4.,  7., 11.,  4.,  9.,  8.,  6., 11.,  7.,  5., 10.,  3.,  6., 15.,\n",
      "         4.,  2., 10.,  2., 10.,  6.], dtype=torch.float64)\n",
      "tensor([26., 21., 20., 25., 12., 22., 20., 11.,  7., 18., 29.,  7., 23., 19.,\n",
      "        14., 30., 12.,  5.,  8., 13.], dtype=torch.float64) tensor([21., 20., 25., 12., 22., 20., 11.,  7., 18., 29.,  7., 23., 19., 14.,\n",
      "        30., 12.,  5.,  8., 13., 17.], dtype=torch.float64)\n",
      "tensor([13., 14., 14., 11.,  3., 15., 12., 16., 10.,  4.,  2., 10., 13., 16.,\n",
      "         8., 15., 24., 18., 15., 15.], dtype=torch.float64) tensor([14., 14., 11.,  3., 15., 12., 16., 10.,  4.,  2., 10., 13., 16.,  8.,\n",
      "        15., 24., 18., 15., 15., 10.], dtype=torch.float64)\n",
      "tensor([3., 1., 2., 1., 1., 0., 0., 0., 1., 0., 1., 2., 2., 1., 1., 2., 4., 3.,\n",
      "        1., 2.], dtype=torch.float64) tensor([1., 2., 1., 1., 0., 0., 0., 1., 0., 1., 2., 2., 1., 1., 2., 4., 3., 1.,\n",
      "        2., 2.], dtype=torch.float64)\n",
      "tensor([7., 4., 2., 3., 6., 3., 8., 3., 1., 1., 3., 1., 0., 3., 2., 2., 9., 2.,\n",
      "        6., 4.], dtype=torch.float64) tensor([4., 2., 3., 6., 3., 8., 3., 1., 1., 3., 1., 0., 3., 2., 2., 9., 2., 6.,\n",
      "        4., 0.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(list(zip(sales,sales_shift)), shuffle=True, batch_size=32) \n",
    "val_loader = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size:  torch.Size([1, 20, 1])\n",
      "Output size:  torch.Size([20, 1])\n",
      "Hidden state size:  torch.Size([2, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.append(\"..\")\n",
    "from rnn import RNN\n",
    "# MSE loss and Adam optimizer with a learning rate of 0.01\n",
    "criterion = nn.MSELoss()\n",
    "# test that dimensions are as expected\n",
    "test_rnn = RNN(input_size=1, output_size=1, hidden_dim=10, n_layers=2, criterion=criterion)\n",
    "\n",
    "# generate evenly spaced, test data pts\n",
    "time_steps = np.linspace(0, np.pi, seq_length)\n",
    "data = np.sin(time_steps)\n",
    "data.resize((seq_length, 1))\n",
    "\n",
    "test_input = torch.Tensor(data).unsqueeze(0) # give it a batch_size of 1 as first dimension\n",
    "print('Input size: ', test_input.size())\n",
    "\n",
    "# test out rnn sizes\n",
    "test_out, test_h = test_rnn(test_input, None)\n",
    "print('Output size: ', test_out.size())\n",
    "print('Hidden state size: ', test_h.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(1, 32, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (criterion): MSELoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# decide on hyperparameters\n",
    "input_size=1 \n",
    "output_size=1\n",
    "hidden_dim=32\n",
    "n_layers=2\n",
    "\n",
    "# instantiate an RNN\n",
    "rnn = RNN(input_size, output_size, hidden_dim, n_layers, criterion=criterion)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss and Adam optimizer with a learning rate of 0.01\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 1)\n",
      "(20, 1)\n",
      "(20, 1)\n",
      "Loss:  0.09375949203968048\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 1)\n",
      "(20, 1)\n",
      "(20, 1)\n"
     ]
    }
   ],
   "source": [
    "n_steps = 2\n",
    "print_every = 15\n",
    "# train the RNN\n",
    "\n",
    "hidden = None      \n",
    "for batch_i, step in enumerate(range(n_steps)):\n",
    "    # defining the training data \n",
    "    time_steps = np.linspace(step * np.pi, (step+1)*np.pi, seq_length + 1)\n",
    "    data = np.sin(time_steps)\n",
    "    data.resize((seq_length + 1, 1)) # input_size=1\n",
    "    print(data.shape)\n",
    "    x = data[:-1]\n",
    "    print(x.shape)\n",
    "    y = data[1:]\n",
    "    print(y.shape)\n",
    "    \n",
    "    # convert data into Tensors\n",
    "    x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension\n",
    "    y_tensor = torch.Tensor(y)\n",
    "\n",
    "    # outputs from the rnn\n",
    "    prediction, hidden = rnn(x_tensor, hidden)\n",
    "\n",
    "    ## Representing Memory ##\n",
    "    # make a new variable for hidden and detach the hidden state from its history\n",
    "    # this way, we don't backpropagate through the entire history\n",
    "    hidden = hidden.data\n",
    "\n",
    "    # calculate the loss\n",
    "    loss = criterion(prediction, y_tensor)\n",
    "    # zero gradients\n",
    "    optimizer.zero_grad()\n",
    "    # perform backprop and update weights\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # display loss and predictions\n",
    "    if batch_i%print_every == 0:        \n",
    "        print('Loss: ', loss.item())\n",
    "        plt.plot(time_steps[1:], x, 'r.') # input\n",
    "        plt.plot(time_steps[1:], prediction.data.numpy().flatten(), 'b.') # predictions\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default_ml_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
